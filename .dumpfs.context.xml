<?xml version="1.0" encoding="UTF-8"?>
<directory_scan timestamp="2025-03-27T00:25:41.226068680+03:00">
  <system_info>
    <hostname>penzu</hostname>
    <os>linux</os>
    <kernel>unix</kernel>
  </system_info>
  <directory name="dumpfs" path="dumpfs">
    <metadata>
      <size>142</size>
      <modified>2025-03-27T00:23:59.136932894+03:00</modified>
      <permissions>755</permissions>
    </metadata>
    <contents>
      <directory name="src" path="dumpfs/src">
        <metadata>
          <size>148</size>
          <modified>2025-03-26T23:40:31.846378173+03:00</modified>
          <permissions>755</permissions>
        </metadata>
        <contents>
          <file name="main.rs" path="dumpfs/src/main.rs">
            <metadata>
              <size>3528</size>
              <modified>2025-03-27T00:25:03.924940764+03:00</modified>
              <permissions>644</permissions>
            </metadata>
            <content>/*!
 * Command-line interface for DumpFS
 */

use std::io;
use std::sync::Arc;
use std::time::Instant;

use clap::Parser;
use indicatif::{ProgressBar, ProgressStyle};
use rayon::ThreadPoolBuilder;

use dumpfs::config::{Args, Config};
use dumpfs::report::{ReportFormat, Reporter, ScanReport};
use dumpfs::scanner::Scanner;
use dumpfs::utils::count_files;
use dumpfs::writer::XmlWriter;

fn main() -&gt; io::Result&lt;()&gt; {
    // Parse command line arguments
    let args = Args::parse();

    // Create configuration
    let config = Config::from_args(args);

    // Validate configuration
    config.validate()?;

    // Configure thread pool
    if let Err(e) = ThreadPoolBuilder::new()
        .num_threads(config.num_threads)
        .build_global()
    {
        eprintln!(&quot;Warning: Failed to set thread pool size: {}&quot;, e);
    }

    // Create progress bar with advanced Unicode styling
    let progress = ProgressBar::new(0);
    progress.set_style(ProgressStyle::default_bar()
        .template(&quot;{spinner:.green} {prefix:.bold.cyan} {wide_msg:.dim.white}\n[{bar:40.gradient(blue,cyan)}] {pos}/{len} ({percent}%)\n‚è±Ô∏è  Elapsed: {elapsed_precise}  Remaining: {eta_precise}  Speed: {per_sec}/s&quot;)
        .unwrap()
        .progress_chars(&quot;‚ñà‚ñà‚ñà‚ñà‚ñà &quot;)
        .tick_chars(&quot;‚†ã‚†ô‚†π‚†∏‚†º‚†¥‚†¶‚†ß‚†á‚†è&quot;));
    progress.enable_steady_tick(std::time::Duration::from_millis(100));
    progress.set_prefix(&quot;üìä Setup&quot;);

    progress.set_message(format!(
        &quot;üìÇ Scanning directory: {}&quot;,
        config.target_dir.display()
    ));

    // Add gitignore status message
    if config.respect_gitignore {
        progress.set_message(match &amp;config.gitignore_path {
            Some(path) =&gt; format!(&quot;üîç Using custom gitignore file: {}&quot;, path.display()),
            None =&gt; &quot;üîç Respecting .gitignore files in the project&quot;.to_string(),
        });
    }

    // Count files for progress tracking
    let total_files = match count_files(&amp;config.target_dir, &amp;config) {
        Ok(count) =&gt; {
            progress.set_message(format!(&quot;üîé Found {} files to process&quot;, count));
            count
        }
        Err(e) =&gt; {
            progress.set_message(format!(&quot;‚ö†Ô∏è Warning: Failed to count files: {}&quot;, e));
            0
        }
    };

    progress.set_length(total_files);
    progress.set_prefix(&quot;üìä Processing&quot;);
    progress.set_message(&quot;Starting scan...&quot;);

    // Create scanner and writer
    let scanner = Scanner::new(config.clone(), Arc::new(progress.clone()));
    let writer = XmlWriter::new(config.clone());

    // Start timing both scan and write operations
    let start_time = Instant::now();

    // Scan directory
    let root_node = scanner.scan()?;

    // Write XML output
    writer.write(&amp;root_node)?;

    // Calculate total duration (scan + write)
    let total_duration = start_time.elapsed();

    // Clear the progress bar
    progress.finish_and_clear();

    // Get scanner statistics
    let scanner_stats = scanner.get_statistics();

    // Prepare the scan report
    let scan_report = ScanReport {
        output_file: config.output_file.display().to_string(),
        duration: total_duration,
        files_processed: scanner_stats.files_processed,
        total_lines: scanner_stats.total_lines,
        total_chars: scanner_stats.total_chars,
        file_details: scanner_stats.file_details,
    };

    // Create a reporter and print the report
    let reporter = Reporter::new(ReportFormat::ConsoleTable);
    reporter.print_report(&amp;scan_report);

    Ok(())
}
</content>
          </file>
          <file name="types.rs" path="dumpfs/src/types.rs">
            <metadata>
              <size>2152</size>
              <modified>2025-03-26T22:36:05.617711743+03:00</modified>
              <permissions>644</permissions>
            </metadata>
            <content>/*!
 * Core types and data structures for the DumpFS application
 */

use std::path::PathBuf;
use std::time::SystemTime;

/// Represents different types of filesystem entries
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum FileType {
    /// Text file with readable content
    TextFile,
    /// Binary file (non-text)
    BinaryFile,
    /// Symbolic link to another file
    Symlink,
    /// Directory containing other entries
    Directory,
    /// Other file types
    Other,
}

/// Metadata about a filesystem entry
#[derive(Debug, Clone)]
pub struct Metadata {
    /// Size in bytes
    pub size: u64,
    /// Last modification time
    pub modified: SystemTime,
    /// File permissions in octal format
    pub permissions: String,
}

/// Represents a directory in the file system
#[derive(Debug, Clone)]
pub struct DirectoryNode {
    /// Directory name
    pub name: String,
    /// Relative path from scan root
    pub path: PathBuf,
    /// Directory metadata
    pub metadata: Metadata,
    /// Directory contents
    pub contents: Vec&lt;Node&gt;,
}

/// Represents a text file
#[derive(Debug, Clone)]
pub struct FileNode {
    /// File name
    pub name: String,
    /// Relative path from scan root
    pub path: PathBuf,
    /// File metadata
    pub metadata: Metadata,
    /// File content (may be None if too large)
    pub content: Option&lt;String&gt;,
}

/// Represents a binary file
#[derive(Debug, Clone)]
pub struct BinaryNode {
    /// File name
    pub name: String,
    /// Relative path from scan root
    pub path: PathBuf,
    /// File metadata
    pub metadata: Metadata,
}

/// Represents a symbolic link
#[derive(Debug, Clone)]
pub struct SymlinkNode {
    /// Link name
    pub name: String,
    /// Relative path from scan root
    pub path: PathBuf,
    /// Link metadata
    pub metadata: Metadata,
    /// Target of the symlink
    pub target: String,
}

/// A generic filesystem node
#[derive(Debug, Clone)]
pub enum Node {
    /// Directory node
    Directory(DirectoryNode),
    /// Text file node
    File(FileNode),
    /// Binary file node
    Binary(BinaryNode),
    /// Symbolic link node
    Symlink(SymlinkNode),
}
</content>
          </file>
          <file name="config.rs" path="dumpfs/src/config.rs">
            <metadata>
              <size>3660</size>
              <modified>2025-03-27T00:25:03.912940762+03:00</modified>
              <permissions>644</permissions>
            </metadata>
            <content>/*!
 * Configuration handling for DumpFS
 */

use std::io;
use std::path::PathBuf;

use clap::Parser;

/// Command-line arguments for DumpFS
#[derive(Parser, Debug)]
#[clap(
    name = &quot;dumpfs&quot;,
    version = env!(&quot;CARGO_PKG_VERSION&quot;),
    about = &quot;Generate XML representation of directory contents for LLM context&quot;,
    long_about = &quot;Creates an XML representation of a directory structure and its contents, designed for providing context to Large Language Models (LLMs).&quot;
)]
pub struct Args {
    /// Target directory to process
    #[clap(default_value = &quot;.&quot;)]
    pub directory_path: String,

    /// Output XML file name
    #[clap(default_value = &quot;.dumpfs.context.xml&quot;)]
    pub output_file: String,

    /// Comma-separated list of patterns to ignore
    #[clap(long, value_delimiter = &apos;,&apos;)]
    pub ignore_patterns: Vec&lt;String&gt;,

    /// Comma-separated list of patterns to include (if specified, only matching files are included)
    #[clap(long, value_delimiter = &apos;,&apos;)]
    pub include_patterns: Vec&lt;String&gt;,

    /// Number of threads to use for processing
    #[clap(long, default_value = &quot;4&quot;)]
    pub threads: usize,

    /// Respect .gitignore files (default: true)
    #[clap(long, default_value = &quot;true&quot;)]
    pub respect_gitignore: bool,

    /// Path to custom .gitignore file
    #[clap(long)]
    pub gitignore_path: Option&lt;String&gt;,
}

/// Application configuration
#[derive(Clone, Debug)]
pub struct Config {
    /// Target directory to process
    pub target_dir: PathBuf,

    /// Output XML file path
    pub output_file: PathBuf,

    /// Patterns to ignore
    pub ignore_patterns: Vec&lt;String&gt;,

    /// Patterns to include (if empty, include all)
    pub include_patterns: Vec&lt;String&gt;,

    /// Number of threads to use for processing
    pub num_threads: usize,

    /// Whether to respect .gitignore files
    pub respect_gitignore: bool,

    /// Path to custom .gitignore file
    pub gitignore_path: Option&lt;PathBuf&gt;,
}

impl Config {
    /// Create configuration from command-line arguments
    pub fn from_args(args: Args) -&gt; Self {
        Self {
            target_dir: PathBuf::from(args.directory_path),
            output_file: PathBuf::from(args.output_file),
            ignore_patterns: args.ignore_patterns,
            include_patterns: args.include_patterns,
            num_threads: args.threads,
            respect_gitignore: args.respect_gitignore,
            gitignore_path: args.gitignore_path.map(PathBuf::from),
        }
    }

    /// Validate the configuration
    pub fn validate(&amp;self) -&gt; io::Result&lt;()&gt; {
        // Check if target directory exists and is readable
        if !self.target_dir.exists() || !self.target_dir.is_dir() {
            return Err(io::Error::new(
                io::ErrorKind::NotFound,
                format!(&quot;Target directory not found: {}&quot;, self.target_dir.display()),
            ));
        }

        // Check if output file directory exists and is writable
        if let Some(parent) = self.output_file.parent() {
            if !parent.exists() &amp;&amp; parent != PathBuf::from(&quot;&quot;) {
                return Err(io::Error::new(
                    io::ErrorKind::NotFound,
                    format!(&quot;Output directory not found: {}&quot;, parent.display()),
                ));
            }
        }

        // Check if custom gitignore file exists
        if let Some(path) = &amp;self.gitignore_path {
            if !path.exists() {
                return Err(io::Error::new(
                    io::ErrorKind::NotFound,
                    format!(&quot;Custom .gitignore file not found: {}&quot;, path.display()),
                ));
            }
        }

        Ok(())
    }
}
</content>
          </file>
          <file name="utils.rs" path="dumpfs/src/utils.rs">
            <metadata>
              <size>4749</size>
              <modified>2025-03-27T00:25:03.921940764+03:00</modified>
              <permissions>644</permissions>
            </metadata>
            <content>/*!
 * Utility functions for DumpFS
 */

use std::io;
use std::path::Path;
use std::sync::Arc;

use ignore::WalkBuilder;
use indicatif::ProgressBar;
use once_cell::sync::Lazy;
use walkdir::WalkDir;

use crate::config::Config;
use crate::scanner::Scanner;

/// Count total files for progress tracking
pub fn count_files(dir: &amp;Path, config: &amp;Config) -&gt; io::Result&lt;u64&gt; {
    let scanner = Scanner::new(config.clone(), Arc::new(ProgressBar::hidden()));
    let mut count = 0;

    if config.respect_gitignore {
        // Use ignore crate&apos;s Walk to handle .gitignore patterns
        let mut walker = WalkBuilder::new(dir);

        // Custom gitignore file if specified
        if let Some(gitignore_path) = &amp;config.gitignore_path {
            walker.add_custom_ignore_filename(gitignore_path);
        }

        for entry in walker.build().filter_map(Result::ok) {
            if entry.file_type().map_or(false, |ft| ft.is_file())
                &amp;&amp; !scanner.should_ignore(entry.path())
                &amp;&amp; scanner.should_include(entry.path())
            {
                count += 1;
            }
        }
    } else {
        // Use walkdir without gitignore support
        for entry in WalkDir::new(dir).into_iter().filter_map(Result::ok) {
            if entry.file_type().is_file()
                &amp;&amp; !scanner.should_ignore(entry.path())
                &amp;&amp; scanner.should_include(entry.path())
            {
                count += 1;
            }
        }
    }

    Ok(count)
}

/// Format a human-readable file size
pub fn format_file_size(size: u64) -&gt; String {
    const KB: u64 = 1024;
    const MB: u64 = KB * 1024;
    const GB: u64 = MB * 1024;

    if size &gt;= GB {
        format!(&quot;{:.2} GB&quot;, size as f64 / GB as f64)
    } else if size &gt;= MB {
        format!(&quot;{:.2} MB&quot;, size as f64 / MB as f64)
    } else if size &gt;= KB {
        format!(&quot;{:.2} KB&quot;, size as f64 / KB as f64)
    } else {
        format!(&quot;{} bytes&quot;, size)
    }
}

/// Default patterns to ignore
pub static DEFAULT_IGNORE: Lazy&lt;Vec&lt;&amp;&apos;static str&gt;&gt; = Lazy::new(|| {
    vec![
        // Version Control
        &quot;.git&quot;,
        &quot;.svn&quot;,
        &quot;.hg&quot;,
        &quot;.bzr&quot;,
        &quot;.gitignore&quot;,
        &quot;.gitattributes&quot;,
        // OS Files
        &quot;.DS_Store&quot;,
        &quot;Thumbs.db&quot;,
        &quot;desktop.ini&quot;,
        &quot;ehthumbs.db&quot;,
        &quot;*.lnk&quot;,
        &quot;*.url&quot;,
        &quot;.directory&quot;,
        // Dependencies
        &quot;node_modules&quot;,
        &quot;bower_components&quot;,
        &quot;.npm&quot;,
        &quot;package-lock.json&quot;,
        &quot;yarn.lock&quot;,
        &quot;.yarn&quot;,
        &quot;vendor&quot;,
        &quot;composer.lock&quot;,
        &quot;.pnpm-store&quot;,
        // Build &amp; Dist
        &quot;dist&quot;,
        &quot;build&quot;,
        &quot;out&quot;,
        &quot;bin&quot;,
        &quot;release&quot;,
        &quot;*.min.js&quot;,
        &quot;*.min.css&quot;,
        &quot;bundle.*&quot;,
        // Python
        &quot;__pycache__&quot;,
        &quot;.pytest_cache&quot;,
        &quot;.coverage&quot;,
        &quot;venv&quot;,
        &quot;env&quot;,
        &quot;.env&quot;,
        &quot;.venv&quot;,
        &quot;*.pyc&quot;,
        &quot;*.pyo&quot;,
        &quot;*.pyd&quot;,
        &quot;.python-version&quot;,
        &quot;*.egg-info&quot;,
        &quot;*.egg&quot;,
        &quot;develop-eggs&quot;,
        // Rust
        &quot;target&quot;,
        &quot;Cargo.lock&quot;,
        &quot;.cargo&quot;,
        // IDEs &amp; Editors
        &quot;.idea&quot;,
        &quot;.vscode&quot;,
        &quot;.vs&quot;,
        &quot;.sublime-*&quot;,
        &quot;*.swp&quot;,
        &quot;*.swo&quot;,
        &quot;*~&quot;,
        &quot;.project&quot;,
        &quot;.settings&quot;,
        &quot;.classpath&quot;,
        &quot;.factorypath&quot;,
        &quot;*.iml&quot;,
        &quot;*.iws&quot;,
        &quot;*.ipr&quot;,
        // Caches &amp; Temp
        &quot;.cache&quot;,
        &quot;tmp&quot;,
        &quot;temp&quot;,
        &quot;logs&quot;,
        &quot;.sass-cache&quot;,
        &quot;.eslintcache&quot;,
        &quot;*.log&quot;,
        &quot;npm-debug.log*&quot;,
        &quot;yarn-debug.log*&quot;,
        &quot;yarn-error.log*&quot;,
        // Other Build Tools
        &quot;.gradle&quot;,
        &quot;gradle&quot;,
        &quot;.maven&quot;,
        &quot;.m2&quot;,
        &quot;*.class&quot;,
        &quot;*.jar&quot;,
        &quot;*.war&quot;,
        &quot;*.ear&quot;,
        // JavaScript/TypeScript
        &quot;coverage&quot;,
        &quot;.nyc_output&quot;,
        &quot;.next&quot;,
        &quot;*.tsbuildinfo&quot;,
        &quot;.nuxt&quot;,
        &quot;.output&quot;,
        // .NET
        &quot;bin&quot;,
        &quot;obj&quot;,
        &quot;Debug&quot;,
        &quot;Release&quot;,
        &quot;packages&quot;,
        &quot;*.suo&quot;,
        &quot;*.user&quot;,
        &quot;*.pubxml&quot;,
        &quot;*.pubxml.user&quot;,
        // Documentation
        &quot;_site&quot;,
        &quot;.jekyll-cache&quot;,
        &quot;.docusaurus&quot;,
        // Mobile Development
        &quot;.gradle&quot;,
        &quot;build&quot;,
        &quot;xcuserdata&quot;,
        &quot;*.xcworkspace&quot;,
        &quot;Pods/&quot;,
        &quot;.expo&quot;,
        // Database
        &quot;*.sqlite&quot;,
        &quot;*.sqlite3&quot;,
        &quot;*.db&quot;,
        // Archives
        &quot;*.zip&quot;,
        &quot;*.tar.gz&quot;,
        &quot;*.tgz&quot;,
        &quot;*.rar&quot;,
        // Kubernetes
        &quot;.kube&quot;,
        &quot;*.kubeconfig&quot;,
        // Terraform
        &quot;.terraform&quot;,
        &quot;*.tfstate&quot;,
        &quot;*.tfvars&quot;,
        // Ansible
        &quot;*.retry&quot;,
    ]
});
</content>
          </file>
          <file name="scanner.rs" path="dumpfs/src/scanner.rs">
            <metadata>
              <size>16254</size>
              <modified>2025-03-27T00:20:30.848916581+03:00</modified>
              <permissions>644</permissions>
            </metadata>
            <content>/*!
 * Directory and file scanning functionality
 */

use std::collections::HashMap;
use std::fs::{self, File};
use std::io::{self, BufRead, BufReader, Read};
use std::os::unix::fs::PermissionsExt;
use std::path::{Path, PathBuf};
use std::sync::{Arc, Mutex};

use glob_match::glob_match;
use ignore::{DirEntry as IgnoreDirEntry, WalkBuilder};
use indicatif::ProgressBar;
use rayon::prelude::*;
use walkdir::{DirEntry, WalkDir};

use crate::config::Config;
use crate::types::{BinaryNode, DirectoryNode, FileNode, FileType, Metadata, Node, SymlinkNode};
use crate::utils::{format_file_size, DEFAULT_IGNORE};

use crate::report::FileReportInfo;

/// Scanner statistics
#[derive(Debug, Clone, Default)]
pub struct ScannerStatistics {
    /// Number of files processed
    pub files_processed: usize,
    /// Total number of lines
    pub total_lines: usize,
    /// Total number of characters
    pub total_chars: usize,
    /// Details for each file
    pub file_details: HashMap&lt;String, FileReportInfo&gt;,
}

/// Scanner for directory contents
pub struct Scanner {
    /// Scanner configuration
    config: Config,
    /// Progress bar
    pub progress: Arc&lt;ProgressBar&gt;,
    /// Scanner statistics
    statistics: Arc&lt;Mutex&lt;ScannerStatistics&gt;&gt;,
}

impl Scanner {
    /// Create a new scanner
    pub fn new(config: Config, progress: Arc&lt;ProgressBar&gt;) -&gt; Self {
        Self {
            config,
            progress,
            statistics: Arc::new(Mutex::new(ScannerStatistics::default())),
        }
    }

    /// Get scanner statistics
    pub fn get_statistics(&amp;self) -&gt; ScannerStatistics {
        self.statistics.lock().unwrap().clone()
    }

    /// Scan the target directory and return the directory tree
    pub fn scan(&amp;self) -&gt; io::Result&lt;DirectoryNode&gt; {
        let abs_path = fs::canonicalize(&amp;self.config.target_dir)?;
        let dir_name = abs_path
            .file_name()
            .unwrap_or_default()
            .to_string_lossy()
            .to_string();

        self.scan_directory(&amp;abs_path, &amp;PathBuf::from(&amp;dir_name))
    }

    /// Scan a directory and return its node representation
    fn scan_directory(&amp;self, abs_path: &amp;Path, rel_path: &amp;Path) -&gt; io::Result&lt;DirectoryNode&gt; {
        let metadata = self.get_metadata(abs_path)?;
        let mut contents = Vec::new();

        // Determine which entries to process based on whether we&apos;re using gitignore
        if self.config.respect_gitignore {
            // Use ignore crate&apos;s Walk to handle .gitignore patterns
            let mut walker = WalkBuilder::new(abs_path);
            walker.max_depth(Some(1)); // Limit depth to just the current directory

            // Use custom gitignore file if specified
            if let Some(gitignore_path) = &amp;self.config.gitignore_path {
                walker.add_custom_ignore_filename(gitignore_path);
            }

            // Get all entries using the ignore walker
            let entries: Vec&lt;IgnoreDirEntry&gt; = walker
                .build()
                .filter_map(Result::ok)
                .filter(|e| e.path() != abs_path) // Skip the root directory itself
                .filter(|e| !self.should_ignore(e.path()))
                .filter(|e| self.should_include(e.path()))
                .collect();

            // Split into directories and files
            let (dirs, files): (Vec&lt;_&gt;, Vec&lt;_&gt;) =
                entries.into_iter().partition(|e| e.path().is_dir());

            // Process directories first (sequential)
            for entry in dirs {
                let entry_path = entry.path();
                let entry_name = entry_path
                    .file_name()
                    .unwrap_or_default()
                    .to_string_lossy()
                    .to_string();
                let new_rel_path = rel_path.join(&amp;entry_name);

                match self.scan_directory(entry_path, &amp;new_rel_path) {
                    Ok(dir_node) =&gt; contents.push(Node::Directory(dir_node)),
                    Err(e) =&gt; {
                        eprintln!(&quot;Error processing directory {}: {}&quot;, entry_path.display(), e)
                    }
                }
            }

            // Process files in parallel
            let file_nodes: Vec&lt;Node&gt; = files
                .par_iter()
                .filter_map(|entry| {
                    let entry_path = entry.path();
                    let entry_name = entry_path
                        .file_name()
                        .unwrap_or_default()
                        .to_string_lossy()
                        .to_string();
                    let new_rel_path = rel_path.join(&amp;entry_name);

                    match self.process_file(entry_path, &amp;new_rel_path) {
                        Ok(node) =&gt; Some(node),
                        Err(e) =&gt; {
                            eprintln!(&quot;Error processing {}: {}&quot;, entry_path.display(), e);
                            None
                        }
                    }
                })
                .collect();

            contents.extend(file_nodes);
        } else {
            // Use traditional walkdir approach when not respecting .gitignore
            let entries: Vec&lt;DirEntry&gt; = WalkDir::new(abs_path)
                .max_depth(1)
                .min_depth(1)
                .into_iter()
                .filter_map(Result::ok)
                .filter(|e| !self.should_ignore(e.path()))
                .filter(|e| self.should_include(e.path()))
                .collect();

            // Split into directories and files
            let (dirs, files): (Vec&lt;_&gt;, Vec&lt;_&gt;) =
                entries.into_iter().partition(|e| e.file_type().is_dir());

            // Process directories first (sequential)
            for entry in dirs {
                let entry_name = entry.file_name().to_string_lossy().to_string();
                let new_rel_path = rel_path.join(&amp;entry_name);

                match self.scan_directory(entry.path(), &amp;new_rel_path) {
                    Ok(dir_node) =&gt; contents.push(Node::Directory(dir_node)),
                    Err(e) =&gt; eprintln!(
                        &quot;Error processing directory {}: {}&quot;,
                        entry.path().display(),
                        e
                    ),
                }
            }

            // Process files in parallel
            let file_nodes: Vec&lt;Node&gt; = files
                .par_iter()
                .filter_map(|entry| {
                    let entry_name = entry.file_name().to_string_lossy().to_string();
                    let new_rel_path = rel_path.join(&amp;entry_name);

                    match self.process_file(entry.path(), &amp;new_rel_path) {
                        Ok(node) =&gt; Some(node),
                        Err(e) =&gt; {
                            eprintln!(&quot;Error processing {}: {}&quot;, entry.path().display(), e);
                            None
                        }
                    }
                })
                .collect();

            contents.extend(file_nodes);
        }

        Ok(DirectoryNode {
            name: abs_path
                .file_name()
                .unwrap_or_default()
                .to_string_lossy()
                .to_string(),
            path: rel_path.to_path_buf(),
            metadata,
            contents,
        })
    }

    /// Process a single file and return its node representation
    fn process_file(&amp;self, abs_path: &amp;Path, rel_path: &amp;Path) -&gt; io::Result&lt;Node&gt; {
        self.progress.inc(1);

        // Update progress message to show current file
        let file_name = abs_path
            .file_name()
            .unwrap_or_default()
            .to_string_lossy()
            .to_string();
        // Update the progress message with the filename
        // Truncate if too long to avoid display issues
        let display_name = if file_name.len() &gt; 40 {
            format!(&quot;...{}&quot;, &amp;file_name[file_name.len().saturating_sub(37)..])
        } else {
            file_name.clone()
        };
        self.progress
            .set_message(format!(&quot;Current file: {}&quot;, display_name));

        let file_type = self.get_file_type(abs_path)?;
        let metadata = self.get_metadata(abs_path)?;
        // Use the relative path for reporting
        let file_path = rel_path.to_string_lossy().to_string();

        match file_type {
            FileType::TextFile =&gt; {
                let content = self.read_file_content(abs_path)?;
                Ok(Node::File(FileNode {
                    name: file_name,
                    path: rel_path.to_path_buf(),
                    metadata,
                    content,
                }))
            }
            FileType::BinaryFile =&gt; {
                // Update statistics for binary files
                {
                    let mut stats = self.statistics.lock().unwrap();
                    stats.files_processed += 1;
                    stats
                        .file_details
                        .insert(file_path, FileReportInfo { lines: 0, chars: 0 });
                }

                Ok(Node::Binary(BinaryNode {
                    name: file_name,
                    path: rel_path.to_path_buf(),
                    metadata,
                }))
            }
            FileType::Symlink =&gt; {
                let target = fs::read_link(abs_path)?.to_string_lossy().to_string();

                // Update statistics for symlinks
                {
                    let mut stats = self.statistics.lock().unwrap();
                    stats.files_processed += 1;
                    stats.file_details.insert(
                        file_path,
                        FileReportInfo {
                            lines: 0,
                            chars: target.chars().count(),
                        },
                    );
                }

                Ok(Node::Symlink(SymlinkNode {
                    name: file_name,
                    path: rel_path.to_path_buf(),
                    metadata,
                    target,
                }))
            }
            _ =&gt; Err(io::Error::new(
                io::ErrorKind::Other,
                format!(&quot;Unexpected file type for {}&quot;, abs_path.display()),
            )),
        }
    }

    /// Check if a file should be ignored based on patterns and defaults
    pub fn should_ignore(&amp;self, path: &amp;Path) -&gt; bool {
        let file_name = path.file_name().unwrap_or_default().to_string_lossy();

        // Check custom ignore patterns
        for pattern in &amp;self.config.ignore_patterns {
            if glob_match(pattern, &amp;file_name) {
                return true;
            }
        }

        // Check default ignore patterns
        if DEFAULT_IGNORE.iter().any(|&amp;p| p == file_name) {
            return true;
        }

        // Don&apos;t process the output file itself
        if path.ends_with(&amp;self.config.output_file) {
            return true;
        }

        false
    }

    /// Check if a file should be included based on patterns
    pub fn should_include(&amp;self, path: &amp;Path) -&gt; bool {
        // If no include patterns, include everything
        if self.config.include_patterns.is_empty() {
            return true;
        }

        let file_name = path.file_name().unwrap_or_default().to_string_lossy();

        // Check against include patterns
        for pattern in &amp;self.config.include_patterns {
            if glob_match(pattern, &amp;file_name) {
                return true;
            }
        }

        false
    }

    /// Determine the type of a file
    fn get_file_type(&amp;self, path: &amp;Path) -&gt; io::Result&lt;FileType&gt; {
        let metadata = fs::metadata(path)?;

        if metadata.is_dir() {
            return Ok(FileType::Directory);
        }

        if metadata.file_type().is_symlink() {
            return Ok(FileType::Symlink);
        }

        if metadata.is_file() {
            // For smaller files, try to detect if they&apos;re text
            if metadata.len() &lt; 8_000_000 {
                // Read a sample of the file to determine type
                let mut buffer = vec![0; std::cmp::min(8192, metadata.len() as usize)];
                if !buffer.is_empty() {
                    let mut file = File::open(path)?;
                    let bytes_read = file.read(&amp;mut buffer)?;
                    buffer.truncate(bytes_read);

                    // Simple heuristic for text files: check for valid UTF-8 and high text-to-binary ratio
                    if String::from_utf8(buffer.clone()).is_ok() {
                        // Count binary characters (0x00-0x08, 0x0E-0x1F)
                        let binary_count = buffer
                            .iter()
                            .filter(|&amp;&amp;b| (b &lt; 9) || (b &gt; 13 &amp;&amp; b &lt; 32))
                            .count();
                        let binary_ratio = binary_count as f32 / buffer.len() as f32;

                        if binary_ratio &lt; 0.1 {
                            return Ok(FileType::TextFile);
                        }
                    }
                }
            }

            // Default to binary for any non-text file
            return Ok(FileType::BinaryFile);
        }

        Ok(FileType::Other)
    }

    /// Extract metadata from a file
    fn get_metadata(&amp;self, path: &amp;Path) -&gt; io::Result&lt;Metadata&gt; {
        let fs_metadata = fs::metadata(path)?;

        Ok(Metadata {
            size: fs_metadata.len(),
            modified: fs_metadata.modified()?,
            permissions: format!(&quot;{:o}&quot;, fs_metadata.permissions().mode() &amp; 0o777),
        })
    }

    /// Read the content of a text file and update statistics
    fn read_file_content(&amp;self, path: &amp;Path) -&gt; io::Result&lt;Option&lt;String&gt;&gt; {
        let metadata = fs::metadata(path)?;
        // Get the relative path from the full path
        let file_path = path.to_string_lossy().to_string();

        // Skip large files
        if metadata.len() &gt; 1_048_576 {
            // 1MB limit
            let message = format!(
                &quot;File too large to include content. Size: {}&quot;,
                format_file_size(metadata.len())
            );

            // Still update statistics for skipped files
            {
                let mut stats = self.statistics.lock().unwrap();
                stats.files_processed += 1;
                stats
                    .file_details
                    .insert(file_path, FileReportInfo { lines: 0, chars: 0 });
            }

            return Ok(Some(message));
        }

        // Read file content
        let mut content = String::new();
        match File::open(path) {
            Ok(file) =&gt; {
                let mut line_count = 0;
                let mut char_count = 0;

                // Count lines and chars
                let reader = BufReader::new(&amp;file);
                for line in reader.lines() {
                    match line {
                        Ok(line) =&gt; {
                            line_count += 1;
                            char_count += line.chars().count();
                            // Add newline char that&apos;s stripped by lines() iterator
                            char_count += 1;
                        }
                        Err(_) =&gt; break,
                    }
                }

                // Re-read file for content
                let mut file = File::open(path)?;
                if let Err(e) = file.read_to_string(&amp;mut content) {
                    return Ok(Some(format!(&quot;Failed to read file content: {}&quot;, e)));
                }

                // Update statistics
                {
                    let mut stats = self.statistics.lock().unwrap();
                    stats.files_processed += 1;
                    stats.total_lines += line_count;
                    stats.total_chars += char_count;
                    stats.file_details.insert(
                        file_path,
                        FileReportInfo {
                            lines: line_count,
                            chars: char_count,
                        },
                    );
                }
            }
            Err(e) =&gt; {
                return Ok(Some(format!(&quot;Failed to open file: {}&quot;, e)));
            }
        }

        Ok(Some(content))
    }
}
</content>
          </file>
          <file name="writer.rs" path="dumpfs/src/writer.rs">
            <metadata>
              <size>7712</size>
              <modified>2025-03-27T00:25:03.922940764+03:00</modified>
              <permissions>644</permissions>
            </metadata>
            <content>/*!
 * XML writer implementation for DumpFS
 */

use std::fs::File;
use std::io::{self, BufWriter, Write};

use chrono::Local;
use quick_xml::events::{BytesDecl, BytesEnd, BytesStart, BytesText, Event};
use quick_xml::Writer;

use crate::config::Config;
use crate::types::{BinaryNode, DirectoryNode, FileNode, Metadata, Node, SymlinkNode};

/// XML writer for directory contents
pub struct XmlWriter {
    /// Writer configuration
    config: Config,
}

impl XmlWriter {
    /// Create a new XML writer
    pub fn new(config: Config) -&gt; Self {
        Self { config }
    }

    /// Write the directory tree to an XML file
    pub fn write(&amp;self, root_node: &amp;DirectoryNode) -&gt; io::Result&lt;()&gt; {
        let file = File::create(&amp;self.config.output_file)?;
        let writer = BufWriter::new(file);
        let mut xml_writer = Writer::new_with_indent(writer, b&apos; &apos;, 2);

        // Write XML declaration
        xml_writer.write_event(Event::Decl(BytesDecl::new(&quot;1.0&quot;, Some(&quot;UTF-8&quot;), None)))?;

        // Start directory_scan element with timestamp
        let mut start_tag = BytesStart::new(&quot;directory_scan&quot;);
        let timestamp = Local::now().to_rfc3339();
        start_tag.push_attribute((&quot;timestamp&quot;, timestamp.as_str()));
        xml_writer.write_event(Event::Start(start_tag))?;

        // Write system info
        self.write_system_info(&amp;mut xml_writer)?;

        // Write directory structure
        self.write_directory(root_node, &amp;mut xml_writer)?;

        // End directory_scan element
        xml_writer.write_event(Event::End(BytesEnd::new(&quot;directory_scan&quot;)))?;

        Ok(())
    }

    /// Write system information to XML
    fn write_system_info&lt;W: Write&gt;(&amp;self, writer: &amp;mut Writer&lt;W&gt;) -&gt; io::Result&lt;()&gt; {
        writer.write_event(Event::Start(BytesStart::new(&quot;system_info&quot;)))?;

        // Write hostname
        writer.write_event(Event::Start(BytesStart::new(&quot;hostname&quot;)))?;
        let hostname = hostname::get()
            .map(|h| h.to_string_lossy().to_string())
            .unwrap_or_else(|_| &quot;unknown&quot;.to_string());
        writer.write_event(Event::Text(BytesText::new(&amp;hostname)))?;
        writer.write_event(Event::End(BytesEnd::new(&quot;hostname&quot;)))?;

        // Write OS
        writer.write_event(Event::Start(BytesStart::new(&quot;os&quot;)))?;
        let os = std::env::consts::OS;
        writer.write_event(Event::Text(BytesText::new(os)))?;
        writer.write_event(Event::End(BytesEnd::new(&quot;os&quot;)))?;

        // Write kernel version
        writer.write_event(Event::Start(BytesStart::new(&quot;kernel&quot;)))?;
        let kernel = std::env::consts::FAMILY;
        writer.write_event(Event::Text(BytesText::new(kernel)))?;
        writer.write_event(Event::End(BytesEnd::new(&quot;kernel&quot;)))?;

        writer.write_event(Event::End(BytesEnd::new(&quot;system_info&quot;)))?;

        Ok(())
    }

    /// Write a directory node to XML
    fn write_directory&lt;W: Write&gt;(
        &amp;self,
        dir: &amp;DirectoryNode,
        writer: &amp;mut Writer&lt;W&gt;,
    ) -&gt; io::Result&lt;()&gt; {
        let mut start_tag = BytesStart::new(&quot;directory&quot;);
        start_tag.push_attribute((&quot;name&quot;, dir.name.as_str()));
        start_tag.push_attribute((&quot;path&quot;, dir.path.to_string_lossy().as_ref()));
        writer.write_event(Event::Start(start_tag))?;

        // Write metadata
        self.write_metadata(&amp;dir.metadata, writer)?;

        // Write contents
        writer.write_event(Event::Start(BytesStart::new(&quot;contents&quot;)))?;

        for node in &amp;dir.contents {
            match node {
                Node::Directory(dir_node) =&gt; self.write_directory(dir_node, writer)?,
                Node::File(file_node) =&gt; self.write_file(file_node, writer)?,
                Node::Binary(bin_node) =&gt; self.write_binary(bin_node, writer)?,
                Node::Symlink(sym_node) =&gt; self.write_symlink(sym_node, writer)?,
            }
        }

        writer.write_event(Event::End(BytesEnd::new(&quot;contents&quot;)))?;
        writer.write_event(Event::End(BytesEnd::new(&quot;directory&quot;)))?;

        Ok(())
    }

    /// Write a file node to XML
    fn write_file&lt;W: Write&gt;(&amp;self, file: &amp;FileNode, writer: &amp;mut Writer&lt;W&gt;) -&gt; io::Result&lt;()&gt; {
        let mut start_tag = BytesStart::new(&quot;file&quot;);
        start_tag.push_attribute((&quot;name&quot;, file.name.as_str()));
        start_tag.push_attribute((&quot;path&quot;, file.path.to_string_lossy().as_ref()));
        writer.write_event(Event::Start(start_tag))?;

        // Write metadata
        self.write_metadata(&amp;file.metadata, writer)?;

        // Write content
        writer.write_event(Event::Start(BytesStart::new(&quot;content&quot;)))?;
        if let Some(content) = &amp;file.content {
            // Split content into chunks and write as text events to avoid XML parsing issues
            for chunk in content.as_bytes().chunks(4096) {
                if let Ok(text) = std::str::from_utf8(chunk) {
                    writer.write_event(Event::Text(BytesText::new(text)))?;
                }
            }
        }
        writer.write_event(Event::End(BytesEnd::new(&quot;content&quot;)))?;

        writer.write_event(Event::End(BytesEnd::new(&quot;file&quot;)))?;

        Ok(())
    }

    /// Write a binary file node to XML
    fn write_binary&lt;W: Write&gt;(
        &amp;self,
        binary: &amp;BinaryNode,
        writer: &amp;mut Writer&lt;W&gt;,
    ) -&gt; io::Result&lt;()&gt; {
        let mut start_tag = BytesStart::new(&quot;binary&quot;);
        start_tag.push_attribute((&quot;name&quot;, binary.name.as_str()));
        start_tag.push_attribute((&quot;path&quot;, binary.path.to_string_lossy().as_ref()));
        writer.write_event(Event::Start(start_tag))?;

        // Write metadata
        self.write_metadata(&amp;binary.metadata, writer)?;

        writer.write_event(Event::End(BytesEnd::new(&quot;binary&quot;)))?;

        Ok(())
    }

    /// Write a symlink node to XML
    fn write_symlink&lt;W: Write&gt;(
        &amp;self,
        symlink: &amp;SymlinkNode,
        writer: &amp;mut Writer&lt;W&gt;,
    ) -&gt; io::Result&lt;()&gt; {
        let mut start_tag = BytesStart::new(&quot;symlink&quot;);
        start_tag.push_attribute((&quot;name&quot;, symlink.name.as_str()));
        start_tag.push_attribute((&quot;path&quot;, symlink.path.to_string_lossy().as_ref()));
        writer.write_event(Event::Start(start_tag))?;

        // Write metadata
        self.write_metadata(&amp;symlink.metadata, writer)?;

        // Write target
        writer.write_event(Event::Start(BytesStart::new(&quot;target&quot;)))?;
        writer.write_event(Event::Text(BytesText::new(&amp;symlink.target)))?;
        writer.write_event(Event::End(BytesEnd::new(&quot;target&quot;)))?;

        writer.write_event(Event::End(BytesEnd::new(&quot;symlink&quot;)))?;

        Ok(())
    }

    /// Write metadata to XML
    fn write_metadata&lt;W: Write&gt;(
        &amp;self,
        metadata: &amp;Metadata,
        writer: &amp;mut Writer&lt;W&gt;,
    ) -&gt; io::Result&lt;()&gt; {
        writer.write_event(Event::Start(BytesStart::new(&quot;metadata&quot;)))?;

        // Write size
        writer.write_event(Event::Start(BytesStart::new(&quot;size&quot;)))?;
        writer.write_event(Event::Text(BytesText::new(&amp;metadata.size.to_string())))?;
        writer.write_event(Event::End(BytesEnd::new(&quot;size&quot;)))?;

        // Write modified time
        writer.write_event(Event::Start(BytesStart::new(&quot;modified&quot;)))?;
        let modified = chrono::DateTime::&lt;chrono::Local&gt;::from(metadata.modified).to_rfc3339();
        writer.write_event(Event::Text(BytesText::new(&amp;modified)))?;
        writer.write_event(Event::End(BytesEnd::new(&quot;modified&quot;)))?;

        // Write permissions
        writer.write_event(Event::Start(BytesStart::new(&quot;permissions&quot;)))?;
        writer.write_event(Event::Text(BytesText::new(&amp;metadata.permissions)))?;
        writer.write_event(Event::End(BytesEnd::new(&quot;permissions&quot;)))?;

        writer.write_event(Event::End(BytesEnd::new(&quot;metadata&quot;)))?;

        Ok(())
    }
}
</content>
          </file>
          <file name="lib.rs" path="dumpfs/src/lib.rs">
            <metadata>
              <size>753</size>
              <modified>2025-03-27T00:25:03.913940762+03:00</modified>
              <permissions>644</permissions>
            </metadata>
            <content>/*!
 * DumpFS - Generate XML representation of directory contents for LLM context
 *
 * This library creates structured XML representations of directory contents
 * for use as context for Large Language Models.
 */

pub mod config;
pub mod report;
pub mod scanner;
pub mod types;
pub mod utils;
pub mod writer;

#[cfg(test)]
mod tests;

// Re-export main components for easier access
pub use config::Config;
pub use report::{FileReportInfo, ReportFormat, Reporter, ScanReport};
pub use scanner::Scanner;
pub use types::{BinaryNode, DirectoryNode, FileNode, FileType, Metadata, Node, SymlinkNode};
pub use utils::{count_files, format_file_size};
pub use writer::XmlWriter;

/// Version of the library
pub const VERSION: &amp;str = env!(&quot;CARGO_PKG_VERSION&quot;);
</content>
          </file>
          <file name="tests.rs" path="dumpfs/src/tests.rs">
            <metadata>
              <size>11423</size>
              <modified>2025-03-27T00:25:03.919940763+03:00</modified>
              <permissions>644</permissions>
            </metadata>
            <content>/*!
 * Tests for DumpFS functionality
 */

#[cfg(test)]
mod tests {
    use std::fs::{self, File};
    use std::io::{self, Write};
    use std::path::Path;
    use std::sync::Arc;

    use indicatif::ProgressBar;
    use quick_xml::events::Event;
    use quick_xml::Reader;
    use tempfile::tempdir;

    use crate::config::Config;
    use crate::scanner::Scanner;
    use crate::writer::XmlWriter;

    // Helper function to create a test directory structure
    fn setup_test_directory() -&gt; io::Result&lt;tempfile::TempDir&gt; {
        let temp_dir = tempdir()?;

        // Create a simple directory structure
        fs::create_dir(temp_dir.path().join(&quot;dir1&quot;))?;
        fs::create_dir(temp_dir.path().join(&quot;dir2&quot;))?;
        fs::create_dir(temp_dir.path().join(&quot;dir1&quot;).join(&quot;subdir&quot;))?;

        // Create text files
        let mut file1 = File::create(temp_dir.path().join(&quot;file1.txt&quot;))?;
        writeln!(file1, &quot;This is a text file with content&quot;)?;

        let mut file2 = File::create(temp_dir.path().join(&quot;dir1&quot;).join(&quot;file2.txt&quot;))?;
        writeln!(file2, &quot;This is another text file\nwith multiple lines&quot;)?;

        let mut file3 = File::create(
            temp_dir
                .path()
                .join(&quot;dir1&quot;)
                .join(&quot;subdir&quot;)
                .join(&quot;file3.txt&quot;),
        )?;
        writeln!(file3, &quot;Nested file content&quot;)?;

        // Create files to be ignored
        fs::create_dir(temp_dir.path().join(&quot;.git&quot;))?;
        let mut git_file = File::create(temp_dir.path().join(&quot;.git&quot;).join(&quot;config&quot;))?;
        writeln!(git_file, &quot;[core]\n\trepositoryformatversion = 0&quot;)?;

        // Create a binary file
        let mut bin_file = File::create(temp_dir.path().join(&quot;binary.bin&quot;))?;
        bin_file.write_all(&amp;[0u8, 1u8, 2u8, 3u8])?;

        // Create a symlink if not on Windows
        #[cfg(not(target_os = &quot;windows&quot;))]
        std::os::unix::fs::symlink(
            temp_dir.path().join(&quot;file1.txt&quot;),
            temp_dir.path().join(&quot;symlink.txt&quot;),
        )?;

        Ok(temp_dir)
    }

    // Helper function to create a test directory with a .gitignore file
    fn setup_gitignore_test_directory() -&gt; io::Result&lt;tempfile::TempDir&gt; {
        let temp_dir = setup_test_directory()?;

        // Create a .gitignore file
        let mut gitignore = File::create(temp_dir.path().join(&quot;.gitignore&quot;))?;
        writeln!(gitignore, &quot;# Ignore all .txt files&quot;)?;
        writeln!(gitignore, &quot;*.txt&quot;)?;
        writeln!(gitignore, &quot;# Ignore binary.bin&quot;)?;
        writeln!(gitignore, &quot;binary.bin&quot;)?;

        // Create some additional files that aren&apos;t explicitly ignored
        let mut not_ignored = File::create(temp_dir.path().join(&quot;not_ignored.md&quot;))?;
        writeln!(not_ignored, &quot;# This file shouldn&apos;t be ignored&quot;)?;

        Ok(temp_dir)
    }

    // Helper function to create a large file (&gt;1MB)
    fn create_large_file(dir: &amp;Path) -&gt; io::Result&lt;()&gt; {
        let path = dir.join(&quot;large_file.txt&quot;);
        let mut file = File::create(path)?;

        // Write over 1MB of data
        let line =
            &quot;This is a line of text that will be repeated many times to create a large file.\n&quot;;
        for _ in 0..20000 {
            file.write_all(line.as_bytes())?;
        }

        Ok(())
    }

    // Test basic scanning functionality
    #[test]
    fn test_basic_scan() -&gt; io::Result&lt;()&gt; {
        let temp_dir = setup_test_directory()?;
        let output_file = temp_dir.path().join(&quot;output.xml&quot;);

        let config = Config {
            target_dir: temp_dir.path().to_path_buf(),
            output_file: output_file.clone(),
            ignore_patterns: vec![],
            include_patterns: vec![],
            num_threads: 1,
            respect_gitignore: false,
            gitignore_path: None,
        };

        let progress = Arc::new(ProgressBar::hidden());
        let scanner = Scanner::new(config.clone(), Arc::clone(&amp;progress));
        let writer = XmlWriter::new(config);

        let root_node = scanner.scan()?;
        writer.write(&amp;root_node)?;

        // Check that the output file exists
        assert!(output_file.exists());

        // Read the XML file to verify structure
        let xml_content = fs::read_to_string(&amp;output_file)?;

        // Check basic structure
        assert!(xml_content.contains(&quot;&lt;directory_scan&quot;));
        assert!(xml_content.contains(&quot;&lt;system_info&gt;&quot;));
        assert!(xml_content.contains(&quot;&lt;hostname&gt;&quot;));
        assert!(xml_content.contains(&quot;&lt;directory name=&quot;));
        assert!(xml_content.contains(&quot;&lt;file name=\&quot;file1.txt\&quot;&quot;));
        assert!(xml_content.contains(&quot;This is a text file with content&quot;));

        // The .git directory should be ignored by default
        assert!(!xml_content.contains(&quot;.git&quot;));

        Ok(())
    }

    // Test ignore patterns
    #[test]
    fn test_ignore_patterns() -&gt; io::Result&lt;()&gt; {
        let temp_dir = setup_test_directory()?;
        let output_file = temp_dir.path().join(&quot;output.xml&quot;);

        let config = Config {
            target_dir: temp_dir.path().to_path_buf(),
            output_file: output_file.clone(),
            ignore_patterns: vec![&quot;*.txt&quot;.to_string()],
            include_patterns: vec![],
            num_threads: 1,
            respect_gitignore: false,
            gitignore_path: None,
        };

        let progress = Arc::new(ProgressBar::hidden());
        let scanner = Scanner::new(config.clone(), Arc::clone(&amp;progress));
        let writer = XmlWriter::new(config);

        let root_node = scanner.scan()?;
        writer.write(&amp;root_node)?;

        // Read the XML file
        let xml_content = fs::read_to_string(&amp;output_file)?;

        // All .txt files should be ignored
        assert!(!xml_content.contains(&quot;file1.txt&quot;));
        assert!(!xml_content.contains(&quot;file2.txt&quot;));
        assert!(!xml_content.contains(&quot;file3.txt&quot;));

        // The binary file should still be included
        assert!(xml_content.contains(&quot;binary.bin&quot;));

        Ok(())
    }

    // Test include patterns
    #[test]
    fn test_include_patterns() -&gt; io::Result&lt;()&gt; {
        let temp_dir = setup_test_directory()?;
        let output_file = temp_dir.path().join(&quot;output.xml&quot;);

        let config = Config {
            target_dir: temp_dir.path().to_path_buf(),
            output_file: output_file.clone(),
            ignore_patterns: vec![],
            include_patterns: vec![&quot;*.bin&quot;.to_string()],
            num_threads: 1,
            respect_gitignore: false,
            gitignore_path: None,
        };

        let progress = Arc::new(ProgressBar::hidden());
        let scanner = Scanner::new(config.clone(), Arc::clone(&amp;progress));
        let writer = XmlWriter::new(config);

        let root_node = scanner.scan()?;
        writer.write(&amp;root_node)?;

        // Read the XML file
        let xml_content = fs::read_to_string(&amp;output_file)?;

        // Only .bin files should be included
        assert!(!xml_content.contains(&quot;file1.txt&quot;));
        assert!(!xml_content.contains(&quot;file2.txt&quot;));
        assert!(!xml_content.contains(&quot;file3.txt&quot;));
        assert!(xml_content.contains(&quot;binary.bin&quot;));

        Ok(())
    }

    // Test handling of large files
    #[test]
    fn test_large_file_handling() -&gt; io::Result&lt;()&gt; {
        let temp_dir = setup_test_directory()?;
        create_large_file(temp_dir.path())?;

        let output_file = temp_dir.path().join(&quot;output.xml&quot;);

        let config = Config {
            target_dir: temp_dir.path().to_path_buf(),
            output_file: output_file.clone(),
            ignore_patterns: vec![],
            include_patterns: vec![],
            num_threads: 1,
            respect_gitignore: false,
            gitignore_path: None,
        };

        let progress = Arc::new(ProgressBar::hidden());
        let scanner = Scanner::new(config.clone(), Arc::clone(&amp;progress));
        let writer = XmlWriter::new(config);

        let root_node = scanner.scan()?;
        writer.write(&amp;root_node)?;

        // Read the XML file
        let xml_content = fs::read_to_string(&amp;output_file)?;

        // Large file should be mentioned but content should be truncated
        assert!(xml_content.contains(&quot;large_file.txt&quot;));
        assert!(xml_content.contains(&quot;File too large to include content&quot;));

        Ok(())
    }

    // Test XML structure validity
    #[test]
    fn test_xml_validity() -&gt; io::Result&lt;()&gt; {
        let temp_dir = setup_test_directory()?;
        let output_file = temp_dir.path().join(&quot;output.xml&quot;);

        let config = Config {
            target_dir: temp_dir.path().to_path_buf(),
            output_file: output_file.clone(),
            ignore_patterns: vec![],
            include_patterns: vec![],
            num_threads: 1,
            respect_gitignore: false,
            gitignore_path: None,
        };

        let progress = Arc::new(ProgressBar::hidden());
        let scanner = Scanner::new(config.clone(), Arc::clone(&amp;progress));
        let writer = XmlWriter::new(config);

        let root_node = scanner.scan()?;
        writer.write(&amp;root_node)?;

        // Parse the XML file to verify it&apos;s well-formed
        let file_content = fs::read_to_string(&amp;output_file)?;
        let mut reader = Reader::from_str(&amp;file_content);

        let mut depth = 0;
        let mut buf = Vec::new();

        loop {
            match reader.read_event_into(&amp;mut buf) {
                Ok(Event::Start(_)) =&gt; depth += 1,
                Ok(Event::End(_)) =&gt; depth -= 1,
                Ok(Event::Eof) =&gt; break,
                Err(e) =&gt; panic!(&quot;Error parsing XML: {}&quot;, e),
                _ =&gt; (),
            }
            buf.clear();
        }

        // If XML is well-formed, depth should be 0 at the end
        assert_eq!(depth, 0, &quot;XML structure is not well-balanced&quot;);

        Ok(())
    }

    // Test respecting .gitignore files
    #[test]
    fn test_respect_gitignore() -&gt; io::Result&lt;()&gt; {
        let temp_dir = setup_gitignore_test_directory()?;
        let output_file = temp_dir.path().join(&quot;output.xml&quot;);

        let config = Config {
            target_dir: temp_dir.path().to_path_buf(),
            output_file: output_file.clone(),
            ignore_patterns: vec![],
            include_patterns: vec![],
            num_threads: 1,
            respect_gitignore: true,
            gitignore_path: None,
        };

        let progress = Arc::new(ProgressBar::hidden());
        let scanner = Scanner::new(config.clone(), Arc::clone(&amp;progress));
        let writer = XmlWriter::new(config);

        let root_node = scanner.scan()?;
        writer.write(&amp;root_node)?;

        // Read the XML file
        let xml_content = fs::read_to_string(&amp;output_file)?;

        // Files excluded by .gitignore should not be present
        assert!(!xml_content.contains(&quot;file1.txt&quot;));
        assert!(!xml_content.contains(&quot;file2.txt&quot;));
        assert!(!xml_content.contains(&quot;file3.txt&quot;));
        assert!(!xml_content.contains(&quot;binary.bin&quot;));

        // Files not excluded by .gitignore should be present
        assert!(xml_content.contains(&quot;not_ignored.md&quot;));

        Ok(())
    }

    // Skip the custom gitignore test for now as it requires more complex setup
    // that&apos;s difficult to reliably implement in a test environment
    // The test_respect_gitignore test above already verifies that .gitignore
    // files are respected, which is the main functionality we care about
}
</content>
          </file>
          <file name="report.rs" path="dumpfs/src/report.rs">
            <metadata>
              <size>8163</size>
              <modified>2025-03-27T00:24:33.955936931+03:00</modified>
              <permissions>644</permissions>
            </metadata>
            <content>/*!
 * Reporting functionality for DumpFS
 *
 * Provides functionality for generating formatted reports of scan results
 * using the tabled library for clean, consistent table rendering.
 */

use std::collections::HashMap;
use std::time::Duration;

use tabled::{
    settings::{object::Columns, Alignment, Modify, Padding, Style},
    Table, Tabled,
};

/// Information about a file in the report
#[derive(Debug, Clone, Default)]
pub struct FileReportInfo {
    /// Number of lines in the file
    pub lines: usize,
    /// Number of characters in the file
    pub chars: usize,
}

/// Statistics for a directory scan
#[derive(Debug, Clone)]
pub struct ScanReport {
    /// Output file path
    pub output_file: String,
    /// Time taken to scan
    pub duration: Duration,
    /// Number of files processed
    pub files_processed: usize,
    /// Total number of lines
    pub total_lines: usize,
    /// Total number of characters
    pub total_chars: usize,
    /// Details for each file
    pub file_details: HashMap&lt;String, FileReportInfo&gt;,
}

/// Format of the report output
pub enum ReportFormat {
    /// Console table output
    ConsoleTable,
    // Other formats could be added in the future
    // JSON, HTML, etc.
}

/// Report generator for scan results
pub struct Reporter {
    format: ReportFormat,
}

impl Reporter {
    /// Create a new reporter
    pub fn new(format: ReportFormat) -&gt; Self {
        Self { format }
    }

    /// Format a number with human-readable units
    fn format_number(&amp;self, num: usize) -&gt; String {
        if num &gt;= 1_000_000 {
            format!(&quot;{:.1}M&quot;, num as f64 / 1_000_000.0)
        } else if num &gt;= 1_000 {
            format!(&quot;{:.1}K&quot;, num as f64 / 1_000.0)
        } else {
            num.to_string()
        }
    }

    /// Generate a report string based on scan statistics
    pub fn generate_report(&amp;self, report: &amp;ScanReport) -&gt; String {
        match self.format {
            ReportFormat::ConsoleTable =&gt; self.generate_console_report(report),
            // Additional formats could be added here
        }
    }

    /// Print the report to stdout
    pub fn print_report(&amp;self, report: &amp;ScanReport) {
        println!(&quot;\n{}&quot;, self.generate_report(report));
    }

    // Format path to be relative and handle truncation if needed
    fn format_path(&amp;self, path: &amp;str, max_len: usize) -&gt; String {
        // Strip leading paths to show only project-relative path
        let parts: Vec&lt;&amp;str&gt; = path.split(&apos;/&apos;).collect();

        // If the path contains &quot;projs/dumpfs&quot;, extract everything after that
        let mut rel_path = path.to_string();
        if let Some(pos) = path.find(&quot;projs/dumpfs&quot;) {
            if let Some(p) = path.get(pos + &quot;projs/dumpfs&quot;.len() + 1..) {
                rel_path = p.to_string();
            }
        }

        // If relative path is empty, use the original filename
        if rel_path.is_empty() &amp;&amp; !parts.is_empty() {
            rel_path = parts.last().unwrap_or(&amp;&quot;&quot;).to_string();
        }

        // Truncate if too long
        if rel_path.len() &lt;= max_len {
            return rel_path;
        }

        // If too long, preserve the most meaningful part (filename and parent dirs)
        let parts: Vec&lt;&amp;str&gt; = path.split(&apos;/&apos;).collect();
        if parts.len() &lt;= 2 {
            return format!(&quot;...{}&quot;, &amp;path[path.len().saturating_sub(max_len - 3)..]);
        }

        // Keep the last few segments
        let mut result = String::new();
        let mut current_len = 3; // Start with &quot;...&quot;
        let mut segments = Vec::new();

        for part in parts.iter().rev() {
            let part_len = part.len() + 1; // +1 for &apos;/&apos;
            if current_len + part_len &lt;= max_len {
                segments.push(*part);
                current_len += part_len;
            } else {
                break;
            }
        }

        result.push_str(&quot;...&quot;);
        for part in segments.iter().rev() {
            result.push(&apos;/&apos;);
            result.push_str(part);
        }

        result
    }

    // Create a summary table using the tabled crate
    fn create_summary_table(&amp;self, report: &amp;ScanReport) -&gt; String {
        // Define the summary table data structure
        #[derive(Tabled)]
        struct SummaryRow {
            #[tabled(rename = &quot;Metric&quot;)]
            key: String,

            #[tabled(rename = &quot;Value&quot;)]
            value: String,
        }

        let mut rows = Vec::new();

        // Add rows to the summary table
        rows.push(SummaryRow {
            key: &quot;üìÇ Output File&quot;.to_string(),
            value: report.output_file.clone(),
        });

        rows.push(SummaryRow {
            key: &quot;‚è±Ô∏è Process Time&quot;.to_string(),
            value: format!(&quot;{:.4?}&quot;, report.duration),
        });

        rows.push(SummaryRow {
            key: &quot;üìÑ Files Processed&quot;.to_string(),
            value: self.format_number(report.files_processed),
        });

        rows.push(SummaryRow {
            key: &quot;üìù Total Lines&quot;.to_string(),
            value: self.format_number(report.total_lines),
        });

        // Calculate token estimate
        let estimated_tokens = report.total_chars / 4;
        let formatted_tokens = self.format_number(estimated_tokens);

        let token_usage = format!(&quot;{} tokens&quot;, formatted_tokens);

        rows.push(SummaryRow {
            key: &quot;üì¶ Estimated LLM Tokens&quot;.to_string(),
            value: token_usage,
        });

        // Create and style the table
        let mut table = Table::new(rows);
        table
            .with(Style::rounded())
            .with(Padding::new(1, 1, 0, 0))
            .with(Modify::new(Columns::new(..)).with(Alignment::left()));

        table.to_string()
    }

    // Create a files table using the tabled crate
    fn create_files_table(&amp;self, report: &amp;ScanReport) -&gt; String {
        // Define the files table data structure
        #[derive(Tabled)]
        struct FileRow {
            #[tabled(rename = &quot;File Path&quot;)]
            path: String,

            #[tabled(rename = &quot;Lines&quot;)]
            lines: String,

            #[tabled(rename = &quot;Est. Tokens&quot;)]
            tokens: String,
        }

        // Sort files by character count
        let mut files: Vec&lt;_&gt; = report.file_details.iter().collect();
        files.sort_by(|(_, a), (_, b)| b.chars.cmp(&amp;a.chars));

        // Determine if we show all files or just top 10
        let files_to_show = if report.file_details.len() &gt; 15 {
            &amp;files[0..10]
        } else {
            &amp;files[..]
        };

        // Generate rows for the table
        let rows: Vec&lt;FileRow&gt; = files_to_show
            .iter()
            .map(|(path, info)| {
                // Format and truncate path if needed
                let display_path = self.format_path(path, 60);

                let estimated_tokens = info.chars / 4;

                FileRow {
                    path: display_path,
                    lines: self.format_number(info.lines),
                    tokens: self.format_number(estimated_tokens),
                }
            })
            .collect();

        // Create and style the table
        let mut table = Table::new(rows);
        table
            .with(Style::rounded())
            .with(Padding::new(1, 1, 0, 0))
            .with(Modify::new(Columns::new(..)).with(Alignment::left()));

        table.to_string()
    }

    // Generate a console table report
    fn generate_console_report(&amp;self, report: &amp;ScanReport) -&gt; String {
        // Generate summary and files tables
        let summary_table = self.create_summary_table(report);
        let files_table = self.create_files_table(report);

        // Create proper section titles
        let summary_title = &quot;‚úÖ  EXTRACTION COMPLETE&quot;;
        let files_title = if report.file_details.len() &gt; 15 {
            &quot;üìã  TOP 10 LARGEST FILES BY CHARACTER COUNT  üìã&quot;
        } else {
            &quot;üìã  PROCESSED FILES&quot;
        };

        // Combine them with appropriate spacing and titles, but put files first
        format!(
            &quot;{}\n{}\n\n{}\n{}&quot;,
            files_title, files_table, summary_title, summary_table
        )
    }
}
</content>
          </file>
        </contents>
      </directory>
      <file name="Cargo.toml" path="dumpfs/Cargo.toml">
        <metadata>
          <size>543</size>
          <modified>2025-03-26T23:54:02.133074349+03:00</modified>
          <permissions>644</permissions>
        </metadata>
        <content>[package]
name = &quot;dumpfs&quot;
version = &quot;0.1.0&quot;
edition = &quot;2021&quot;
description = &quot;Generate XML representation of directory contents for LLM context&quot;
authors = [&quot;DumpFS Team&quot;]
license = &quot;MIT&quot;

[dependencies]
clap = { version = &quot;4.3&quot;, features = [&quot;derive&quot;] }
walkdir = &quot;2.3&quot;
quick-xml = &quot;0.37.3&quot;
rayon = &quot;1.7&quot;
indicatif = &quot;0.17&quot;
glob-match = &quot;0.2&quot;
chrono = &quot;0.4&quot;
once_cell = &quot;1.18&quot;
hostname = &quot;0.4.0&quot;
ignore = &quot;0.4.21&quot;
tabled = &quot;0.18.0&quot;

[dev-dependencies]
tempfile = &quot;3.8&quot;

[profile.release]
lto = true
codegen-units = 1
panic = &quot;abort&quot;
strip = true
</content>
      </file>
      <file name="README.md" path="dumpfs/README.md">
        <metadata>
          <size>6667</size>
          <modified>2025-03-27T00:24:20.430935307+03:00</modified>
          <permissions>644</permissions>
        </metadata>
        <content># DumpFS: Directory Context Generator for LLMs

`dumpfs` is a command-line tool that generates an XML representation of directory contents, designed specifically for providing context to Large Language Models (LLMs) for coding tasks.

## Features

- Recursively scans directories and generates structured XML output
- Includes file content with CDATA wrapping
- Handles different file types (text, binary, symlinks)
- Provides file metadata (size, modification time, permissions)
- Supports pattern-based inclusion and exclusion of files
- Respects `.gitignore` files for intelligent filtering
- Parallel processing for better performance
- Progress tracking with ETA and detailed file statistics
- Beautiful Unicode progress display with real-time file information
- Comprehensive summary of scanned content with LLM token estimation

## Installation

### From Source

```bash
git clone https://github.com/kkharji/dumpfs.git
cd dumpfs
cargo build --release
```

The binary will be available at `target/release/dumpfs`.

## Usage

```
dumpfs [DIRECTORY_PATH] [OUTPUT_FILE] [OPTIONS]

OPTIONS:
    --ignore-patterns &lt;pattern1,pattern2,...&gt;    Comma-separated list of patterns to ignore
    --include-patterns &lt;pattern1,pattern2,...&gt;   Comma-separated list of patterns to include
    --threads &lt;N&gt;                                Number of threads to use for processing
    --respect-gitignore &lt;BOOL&gt;                   Whether to respect .gitignore files (default: true)
    --gitignore-path &lt;PATH&gt;                      Path to custom .gitignore file
```

When running the command, you&apos;ll see a beautiful progress display showing:

- Real-time progress with an animated spinner
- Current file being processed
- Progress bar showing completion percentage
- Processing speed (files per second)
- Estimated time remaining

After completion, you&apos;ll get a comprehensive summary showing file statistics and token estimation for LLM usage.

### Examples

```bash
# Process current directory
dumpfs

# Process specific directory with custom output file
dumpfs /path/to/project project_context.xml

# Ignore specific patterns
dumpfs --ignore-patterns &quot;*.log,*.tmp,*.bak&quot;

# Include only specific patterns
dumpfs --include-patterns &quot;*.rs,*.toml,*.md&quot;

# Use 8 threads for processing
dumpfs --threads 8

# Disable .gitignore respect
dumpfs --respect-gitignore false

# Use custom gitignore file
dumpfs --gitignore-path /path/to/custom/gitignore
```

## GitIgnore Support

By default, `dumpfs` respects `.gitignore` files in the project directory. This means that files and directories that would be ignored by Git are also ignored by `dumpfs`. This is useful for excluding build artifacts, dependencies, and other files that are not relevant to the codebase.

You can disable this behavior with the `--respect-gitignore false` option, or specify a custom gitignore file with the `--gitignore-path` option.

## Output Format

The tool generates an XML file with the following structure:

```xml
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;directory_scan timestamp=&quot;2025-03-26T12:34:56+00:00&quot;&gt;
  &lt;system_info&gt;
    &lt;hostname&gt;your-hostname&lt;/hostname&gt;
    &lt;os&gt;linux&lt;/os&gt;
    &lt;kernel&gt;unix&lt;/kernel&gt;
  &lt;/system_info&gt;
  &lt;directory name=&quot;project&quot; path=&quot;project&quot;&gt;
    &lt;metadata&gt;
      &lt;size&gt;4096&lt;/size&gt;
      &lt;modified&gt;2025-03-26T12:34:56+00:00&lt;/modified&gt;
      &lt;permissions&gt;755&lt;/permissions&gt;
    &lt;/metadata&gt;
    &lt;contents&gt;
      &lt;file name=&quot;example.rs&quot; path=&quot;project/example.rs&quot;&gt;
        &lt;metadata&gt;
          &lt;size&gt;1024&lt;/size&gt;
          &lt;modified&gt;2025-03-26T12:34:56+00:00&lt;/modified&gt;
          &lt;permissions&gt;644&lt;/permissions&gt;
        &lt;/metadata&gt;
        &lt;content&gt;&lt;![CDATA[fn main() {
    println!(&quot;Hello, world!&quot;);
}]]&gt;&lt;/content&gt;
      &lt;/file&gt;
      &lt;!-- More files and directories --&gt;
    &lt;/contents&gt;
  &lt;/directory&gt;
&lt;/directory_scan&gt;
```

## Example Output

When running `dumpfs`, you&apos;ll initially see scanning messages and a progress bar:

```
üìÇ Scanning directory: .
üîç Respecting .gitignore files in the project
üîé Found 12 files to process
```

During processing, you&apos;ll see a beautiful progress display showing which files are being processed in real-time with an animated progress bar.

After completion, the progress information is automatically cleared, and you&apos;ll see a comprehensive summary with the processed files followed by extraction statistics:

```
üìã  PROCESSED FILES
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ File Path      ‚îÇ Lines ‚îÇ Est. Tokens ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ src/scanner.rs ‚îÇ 461   ‚îÇ 4.1K        ‚îÇ
‚îÇ src/tests.rs   ‚îÇ 330   ‚îÇ 2.9K        ‚îÇ
‚îÇ src/report.rs  ‚îÇ 272   ‚îÇ 2.1K        ‚îÇ
‚îÇ src/writer.rs  ‚îÇ 202   ‚îÇ 2.0K        ‚îÇ
‚îÇ README.md      ‚îÇ 170   ‚îÇ 1.5K        ‚îÇ
‚îÇ src/utils.rs   ‚îÇ 209   ‚îÇ 1.2K        ‚îÇ
‚îÇ src/config.rs  ‚îÇ 119   ‚îÇ 928         ‚îÇ
‚îÇ src/main.rs    ‚îÇ 113   ‚îÇ 870         ‚îÇ
‚îÇ src/types.rs   ‚îÇ 95    ‚îÇ 538         ‚îÇ
‚îÇ src/lib.rs     ‚îÇ 27    ‚îÇ 188         ‚îÇ
‚îÇ Cargo.toml     ‚îÇ 29    ‚îÇ 135         ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

‚úÖ  EXTRACTION COMPLETE
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Metric                  ‚îÇ Value               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ üìÇ Output File          ‚îÇ .dumpfs.context.xml ‚îÇ
‚îÇ ‚è±Ô∏è Process Time         ‚îÇ 7.647ms             ‚îÇ
‚îÇ üìÑ Files Processed      ‚îÇ 12                  ‚îÇ
‚îÇ üìù Total Lines          ‚îÇ 2.1K                ‚îÇ
‚îÇ üì¶ Estimated LLM Tokens ‚îÇ 16.7K tokens        ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

The output provides:
- A detailed breakdown of each file with line counts and token estimates
- File paths displayed relative to the project root
- Human-readable numbers with K suffixes for large values
- Total processing time with millisecond precision
- Total number of files processed
- Total line count
- Estimated token usage for LLM context

This information is particularly valuable when preparing context for LLMs, as it helps you understand the size and composition of the context you&apos;re providing.

## License

MIT
</content>
      </file>
    </contents>
  </directory>
</directory_scan>